import os
import time
import argparse
import subprocess
import pandas as pd


def parse_args():
    parser = argparse.ArgumentParser(description="Molecular Networking Annotation.")
    parser.add_argument(
        "--edited_molecular_network_file",
        default="source_target_cor_edit.csv",
        type=str,
        required=True,
        help="input molecular network file containing source, target, corrrelation",
    )
    parser.add_argument(
        "--seednode_file",
        type=str,
        required=True,
        help="seed node file containing ID and SMILES",
    )
    parser.add_argument(
        "--candidates_folder",
        type=str,
        help="the candidates folder to save the search results",
    )
    parser.add_argument(
        "--num_containers",
        default=10,
        type=int,
        required=True,
        help="the number of Docker containers to run in parallel",
    )
    parser.add_argument(
        "--tolerance",
        default=0.1,
        type=float,
        required=True,
        help="the tolerance for the modified cosine similarity calculation",
    )
    parser.add_argument(
        "--energy_level",
        default=0,
        type=int,
        required=True,
        choices=[0, 1, 2],
        help="the energy level of the spectrum data predicted by CFM-ID, 0 represents low, 1 represents medium, and 2 represents high energy level",
    )
    parser.add_argument(
        "--ion_mode",
        default="positive",
        type=str,
        required=True,
        choices=["positive", "negative"],
        help="the ion mode of the spectrum data predicted by CFM-ID, positive or negative",
    )
    parser.add_argument(
        "--modified_cosine_similarity_threshold",
        default=0.5,
        type=float,
        required=True,
        help="the threshold for modified cosine similarity to filter the results",
    )
    parser.add_argument(
        "--spectrum_file",
        default="./test_files/compounds_spectrum.mgf",
        type=str,
        required=True,
        help="the mgf file containing target node spectra",
    )
    parser.add_argument(
        "--top_k",
        type=int,
        required=True,
        default=10,
        help="the top k candidates for annotation",
    )
    parser.add_argument(
        "--max_iterations",
        default=100,
        type=int,
        required=True,
        help="the maximum number of iterations to run the annotation process",
    )
    return parser.parse_args()


def merge_cfmid_results(cfmid_score_results_path, output_file, cfmid_seednodes_path):
    id_to_round = {}
    round_num = int(
        file.replace("annotation_with_cfmid_seednode_round", "").replace(".csv", "")
    )
    round_df = pd.read_csv(os.path.join(cfmid_seednodes_path, file))
    for id_val in round_df["ID"].dropna().unique():
        id_to_round[str(id_val)] = round_num  # ä¿è¯ key æ˜¯å­—ç¬¦ä¸²æ ¼å¼

    all_files = [f for f in os.listdir(cfmid_score_results_path) if f.endswith(".csv")]
    df_list = []

    for file in all_files:
        file_path = os.path.join(cfmid_score_results_path, file)
        df = pd.read_csv(file_path)
        # æå–IDå¹¶æ·»åŠ ä¸ºç¬¬ä¸€åˆ—
        id_value = file.split(".")[0]  # å‡è®¾æ–‡ä»¶åæ ¼å¼ä¸º ID.csv
        # åˆ¤æ–­id_valueæ˜¯å¦å­˜åœ¨äº id_to_round ä¸­
        if id_value not in id_to_round:
            continue

        df.insert(0, "ID", id_value)  # æ’å…¥åˆ°ç¬¬ä¸€åˆ—

        df.rename(columns={"Seednode": "Seed Node"}, inplace=True)
        df.rename(columns={"CFM-ID_score": "Score"}, inplace=True)
        df.rename(columns={"MW": "MonoIsotopic Weight"}, inplace=True)

        columns_to_keep = [
            "ID",
            "Seed Node",
            "CID",
            "MonoIsotopic Weight",
            "SMILES",
            "Formula",
            "Score",
        ]
        df_final = df[columns_to_keep].copy()

        df_final.sort_values(by="Score", ascending=False, inplace=True)

        # æ·»åŠ  Round åˆ—ä½œä¸ºç¬¬ä¸€åˆ—
        round_value = id_to_round.get(str(id_value), "")
        df_final.insert(0, "Round", round_value)

        df_list.append(df_final)

    # åˆå¹¶æ‰€æœ‰DataFrame
    final_df = pd.concat(df_list, ignore_index=True)
    final_df.to_csv(output_file, index=False)
    print(f"All results merged into {output_file}")


if __name__ == "__main__":
    start_time = time.time()
    args = parse_args()
    # åˆå§‹çš„seednode file
    seednode_file = args.seednode_file
    if not os.path.exists("tmp"):
        os.makedirs("tmp")
    shutil.copy(seednode_file, "tmp/annotation_with_cfmid_seednode_round0.csv")

    last_cycle_seednode_df = pd.read_csv(seednode_file)
    last_cycle_ids = set(last_cycle_seednode_df["ID"].astype(int).tolist())

    # è¯»å– all_nodes é›†åˆ
    molecular_network_df = pd.read_csv(args.edited_molecular_network_file)
    source_nodes = molecular_network_df["source"].tolist()
    target_nodes = molecular_network_df["target"].tolist()

    # å¾ªç¯ç›´åˆ° seednode ä¸­åŒ…å«æ‰€æœ‰èŠ‚ç‚¹
    max_rounds = args.max_iterations  # é˜²æ­¢æ­»å¾ªç¯ï¼Œä½ ä¹Ÿå¯ä»¥å»æ‰
    round_num = 0

    while round_num < max_rounds:
        round_time = time.time()
        round_num += 1
        print(f"\nğŸ” Round {round_num} running...")

        # ä¾æ¬¡è¿è¡Œä¸‰ä¸ªè„šæœ¬
        subprocess.run(
            [
                "python",
                "preprocess.py",
                "--edited_molecular_network_file",
                args.edited_molecular_network_file,
                "--seednode_file",
                seednode_file,
                "--candidates_folder",
                args.candidates_folder,
                "--top_k",
                str(args.top_k),
                "--round_num",
                str(round_num),
            ],
            check=True,
        )
        subprocess.run(
            [
                "python",
                "cfmid_prediction.py",
                "--num_containers",
                str(args.num_containers),
                "--tolerance",
                str(args.tolerance),
                "--energy_level",
                str(args.energy_level),
                "--ion_mode",
                args.ion_mode,
                "--spectrum_file",
                args.spectrum_file,
                "--top_k",
                str(args.top_k),
                "--modified_cosine_similarity_threshold",
                str(args.modified_cosine_similarity_threshold),
                "--round_num",
                str(round_num),
            ],
            check=True,
        )
        subprocess.run(
            [
                "python",
                "postprocess.py",
                "--seednode_file",
                seednode_file,
                "--round_num",
                str(round_num),
            ],
            check=True,
        )

        seednode_file = f"tmp/annotation_with_cfmid_seednode_round{round_num}.csv"
        # è¯»å– seednode æ–‡ä»¶ï¼Œæ£€æŸ¥ ID é›†åˆ
        try:
            seednode_df = pd.read_csv(seednode_file)
            current_ids = set(seednode_df["ID"].astype(int).tolist())
        except Exception as e:
            print(f"âŒ Failed to read seednode.csv: {e}")
            break

        # åˆ¤æ–­æ˜¯å¦å®Œæˆ
        if last_cycle_ids < current_ids:
            last_cycle_ids = current_ids
        else:
            round_num -= 1  # å¦‚æœæ²¡æœ‰æ–°å¢IDï¼Œåˆ™æ³¨é‡Šå®Œæˆï¼Œåˆ™round_numå‡1ï¼Œç¡®ä¿æœ€ç»ˆè¾“å‡ºçš„è¿­ä»£æ¬¡æ•°æ˜¯å®é™…çš„
            print("ğŸ‰ æ³¨é‡Šå®Œæˆï¼")
            break
        print("Round time: ", time.time() - round_time)
    else:
        print("âš ï¸ è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°ï¼Œä»æœªå®Œæˆã€‚")

    # è¾“å‡ºæœ€ç»ˆçš„æ³¨é‡Šç»“æœ
    merge_cfmid_results(
        cfmid_score_results_path="tmp/cfmid_score_results/",
        output_file="final_cfmid_annotation_results.csv",
        cfmid_seednodes_path=f"tmp/annotation_with_cfmid_seednode_round{round_num}.csv",
    )
    print("Spend time: ", time.time() - start_time)
